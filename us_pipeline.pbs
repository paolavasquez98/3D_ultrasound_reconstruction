#!/bin/sh
#PBS -N extract2
#PBS -l nodes=1:gpu48:ppn=1:gpus=1 
#PBS -l mem=32gb  
#PBS -l walltime=20:00:00 
#PBS -q gpu  # GPU queue
#PBS -o logs/log2.log  #  output log
#PBS -e logs/error2.log   # Error log
#PBS -m ae 
#PBS -M paola.vasquez@creatis.insa-lyon.fr

# Move to the working directory
cd $PBS_O_WORKDIR

# Activate Conda  
source ~/.bashrc
conda activate newEnv 

# Get other sources for the data generation
# echo "Getting extra data..."
# python -u get_extra_data.py

Generate the scatterers from different models, especify the amount ot shapes to generate. For meshes and foreground scatterers, the number is already set. For Heart mesh, the maximum is 24.
echo "Generating scatterers..."
python generate_scatterers.py --chambers 50 --ellipsoids 50 --empty_ellipsoid 50 --heart_mesh 24

# Generate the raw I/Q data with 9 DWs and 81DWs from the scatterers
echo "Generating I/Q data..."
for mode in empty_ellip three_ellip mesh two_chambers; do
  matlab -nodisplay -nosplash -batch "process_scatterers('$mode')" > logs/beamform_${mode}.log 2>&1
done

# Create the dataset in a h5 file using the beamformed data. It is posible to specify the number of files to include in the dataset.
echo "Creating dataset..."
python create_dataset.py 

# Deep learning training and testing
echo "Training and testing the model..."
python train_nn.py --no_wandb --config_path configs/Unet.yaml > logs/train_output.log 2>&1